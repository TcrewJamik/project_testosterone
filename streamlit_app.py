# ------------------------ –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ------------------------
with st.sidebar:
    st.header("üõ†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")

    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_choice = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", "CatBoost", "XGBoost", "Decision Tree", "Random Forest"]
    )

    # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    hyperparams = {}
    if model_choice == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è":
        hyperparams['C'] = st.slider("C (–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)", 0.001, 10.0, 1.0, step=0.01)
        penalty_options = ['l1', 'l2', 'none']
        hyperparams['penalty'] = st.selectbox("Penalty", penalty_options, index=1)
        solver_options = ['lbfgs', 'liblinear']
        if hyperparams['penalty'] == 'l1':
            solver_options = ['liblinear', 'saga']
        elif hyperparams['penalty'] == 'none':
            solver_options = ['lbfgs', 'newton-cg', 'sag', 'saga']
        hyperparams['solver'] = st.selectbox("Solver", solver_options, index=0)

    elif model_choice == "CatBoost":
        hyperparams['depth'] = st.slider("–ì–ª—É–±–∏–Ω–∞ (depth)", 4, 10, 6, step=1)
        hyperparams['iterations'] = st.slider("Iterations", 50, 300, 200, step=10)
        hyperparams['learning_rate'] = st.slider("Learning rate", 0.01, 0.5, 0.1, step=0.01)

    elif model_choice == "XGBoost":
        hyperparams['max_depth'] = st.slider("max_depth", 3, 10, 6, step=1)
        hyperparams['n_estimators'] = st.slider("n_estimators", 50, 300, 200, step=10)
        hyperparams['learning_rate'] = st.slider("learning_rate", 0.01, 0.5, 0.1, step=0.01)
        hyperparams['scale_pos_weight'] = st.slider("scale_pos_weight", 1, 10, 1, step=1)

    elif model_choice == "Decision Tree":
        hyperparams['criterion'] = st.selectbox("Criterion", ['gini', 'entropy'], index=0)
        hyperparams['max_depth'] = st.slider("max_depth", 1, 20, 5, step=1)
        hyperparams['min_samples_split'] = st.slider("min_samples_split", 2, 20, 2, step=1)
        hyperparams['min_samples_leaf'] = st.slider("min_samples_leaf", 1, 10, 1, step=1)

    elif model_choice == "Random Forest":
        hyperparams['n_estimators'] = st.slider("n_estimators", 50, 300, 200, step=10)
        hyperparams['max_depth'] = st.slider("max_depth", 1, 20, 10, step=1)
        hyperparams['min_samples_split'] = st.slider("min_samples_split", 2, 20, 2, step=1)
        hyperparams['min_samples_leaf'] = st.slider("min_samples_leaf", 1, 10, 1, step=1)

    # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    selected_features = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:",
        feature_names,
        default=feature_names  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ
    )

    # –ö–Ω–æ–ø–∫–∞ –æ–±—É—á–µ–Ω–∏—è
    train_button = st.button("üî• –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")

    # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è)
    if 'clf' in st.session_state:
        st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π")
        prediction_data = {}
        for feature in selected_features:
            min_val = float(X_train[feature].min())
            max_val = float(X_train[feature].max())
            default_val = float(X_train[feature].mean())
            prediction_data[feature] = st.slider(
                f"–ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {feature}:",
                min_val,
                max_val,
                default_val
            )

        # –ö–Ω–æ–ø–∫–∞ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        single_predict_button = st.button("‚ú® –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞")
