import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score, precision_score, 
                             recall_score, roc_curve, auc, confusion_matrix, classification_report)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
import requests, io

st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –¥–µ—Ñ–∏—Ü–∏—Ç–∞ —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞", page_icon="‚öôÔ∏è", layout="wide")
st.title("–ê–Ω–∞–ª–∏–∑ –¥–µ—Ñ–∏—Ü–∏—Ç–∞ —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞")

# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ GitHub
raw_url = "https://raw.githubusercontent.com/TcrewJamik/project_testosterone/refs/heads/master/ptestost.xlsx"
try:
    response = requests.get(raw_url)
    response.raise_for_status()
    excel_file = io.BytesIO(response.content)
    df = pd.read_excel(excel_file)
    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤
    df = df.rename(columns={
        'Age': '–í–æ–∑—Ä–∞—Å—Ç',
        'DM': '–ù–∞–ª–∏—á–∏–µ –î–∏–∞–±–µ—Ç–∞',
        'TG': '–¢—Ä–∏–≥–ª–∏—Ü–µ—Ä–∏–¥—ã (–º–≥/–¥–ª)',
        'HT': '–ù–∞–ª–∏—á–∏–µ –ì–∏–ø–µ—Ä—Ç–æ–Ω–∏–∏',
        'HDL': 'HDL_—Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω',
        'AC': '–û–∫—Ä—É–∂–Ω–æ—Å—Ç—å_—Ç–∞–ª–∏–∏',
        'T': '–î–µ—Ñ–∏—Ü–∏—Ç –¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞'
    })
    st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ raw —Å—Å—ã–ª–∫–∏ GitHub!")
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    st.stop()

# –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö"):
    st.dataframe(df.head())
    st.write("–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    st.dataframe(df.describe())
    st.write("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    st.write(df.isna().sum())

with st.expander("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"):
    st.subheader("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    for i, column in enumerate(df.columns):
        if i < 6:  # –í—ã–≤–æ–¥–∏–º –ø–µ—Ä–≤—ã–µ 6 —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞
            sns.histplot(df[column], bins=30, kde=True, ax=axes[i//3, i%3])
            axes[i//3, i%3].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {column}')
    st.pyplot(fig)
    
    st.subheader("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    fig_corr = plt.figure(figsize=(10, 8))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
    st.pyplot(fig_corr)

# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
target = df['–î–µ—Ñ–∏—Ü–∏—Ç –¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞']
X = df.drop(columns=['–î–µ—Ñ–∏—Ü–∏—Ç –¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞'])
y = target

# –ï—Å–ª–∏ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∏—Ö –∫–æ–¥–∏—Ä—É–µ–º
non_numeric = X.select_dtypes(include=['object']).columns
if len(non_numeric) > 0:
    le = LabelEncoder()
    for col in non_numeric:
        X[col] = le.fit_transform(X[col])

# –†–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
feature_names = X.columns.tolist()

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å: –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω—ã–π —Ä–∞–∑–¥–µ–ª –≤—ã–±–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
with st.sidebar:
    st.header("üõ†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")
    model_choice = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:", 
                                ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", "CatBoost", "XGBoost", "Decision Tree", "Random Forest"])
    hyperparams = {}
    if model_choice == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è":
        hyperparams['C'] = st.slider("C (–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)", 0.001, 10.0, 1.0, step=0.01)
        penalty_options = ['l1', 'l2', 'none']
        hyperparams['penalty'] = st.selectbox("Penalty", penalty_options, index=1)
        solver_options = ['lbfgs', 'liblinear']
        if hyperparams['penalty'] == 'l1':
            solver_options = ['liblinear', 'saga']
        elif hyperparams['penalty'] == 'none':
            solver_options = ['lbfgs', 'newton-cg', 'sag', 'saga']
        hyperparams['solver'] = st.selectbox("Solver", solver_options, index=0)
    elif model_choice == "CatBoost":
        hyperparams['depth'] = st.slider("–ì–ª—É–±–∏–Ω–∞ (depth)", 4, 10, 6, step=1)
        hyperparams['iterations'] = st.slider("Iterations", 50, 300, 200, step=10)
        hyperparams['learning_rate'] = st.slider("Learning rate", 0.01, 0.5, 0.1, step=0.01)
    elif model_choice == "XGBoost":
        hyperparams['max_depth'] = st.slider("max_depth", 3, 10, 6, step=1)
        hyperparams['n_estimators'] = st.slider("n_estimators", 50, 300, 200, step=10)
        hyperparams['learning_rate'] = st.slider("learning_rate", 0.01, 0.5, 0.1, step=0.01)
        hyperparams['scale_pos_weight'] = st.slider("scale_pos_weight", 1, 10, 1, step=1)
    elif model_choice == "Decision Tree":
        hyperparams['criterion'] = st.selectbox("Criterion", ['gini', 'entropy'], index=0)
        hyperparams['max_depth'] = st.slider("max_depth", 1, 20, 5, step=1)
        hyperparams['min_samples_split'] = st.slider("min_samples_split", 2, 20, 2, step=1)
        hyperparams['min_samples_leaf'] = st.slider("min_samples_leaf", 1, 10, 1, step=1)
    elif model_choice == "Random Forest":
        hyperparams['n_estimators'] = st.slider("n_estimators", 50, 300, 200, step=10)
        hyperparams['max_depth'] = st.slider("max_depth", 1, 20, 10, step=1)
        hyperparams['min_samples_split'] = st.slider("min_samples_split", 2, 20, 2, step=1)
        hyperparams['min_samples_leaf'] = st.slider("min_samples_leaf", 1, 10, 1, step=1)
    
    st.markdown("---")
    st.header("üìä –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –µ–¥–∏–Ω–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
    available_features = feature_names
    default_features = available_features  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—ã–±–∏—Ä–∞—é—Ç—Å—è –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    selected_features = st.multiselect("–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:", 
                                       available_features, default=default_features)
    # –ö–Ω–æ–ø–∫–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    train_button = st.button("üî• –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")
    
    st.markdown("---")
    st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
    prediction_data = {}
    if selected_features:
        for feature in selected_features:
            min_val = float(X_train[feature].min())
            max_val = float(X_train[feature].max())
            default_val = float(X_train[feature].mean())
            prediction_data[feature] = st.slider(f"–ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {feature}:", min_val, max_val, default_val)
    single_predict_button = st.button("‚ú® –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞")

# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏ –æ—Ü–µ–Ω–∫–∞
if train_button:
    if not selected_features:
        st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
    else:
        # –û—Ç–±–æ—Ä —Å—Ç–æ–ª–±—Ü–æ–≤ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º
        selected_idx = [feature_names.index(feat) for feat in selected_features]
        X_train_sel = X_train_scaled[:, selected_idx]
        X_test_sel = X_test_scaled[:, selected_idx]
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –≤—ã–±—Ä–∞–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        if model_choice == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è":
            clf = LogisticRegression(random_state=42, max_iter=1000, **hyperparams)
        elif model_choice == "CatBoost":
            clf = CatBoostClassifier(random_state=42, verbose=0, **hyperparams)
        elif model_choice == "XGBoost":
            clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **hyperparams)
        elif model_choice == "Decision Tree":
            clf = DecisionTreeClassifier(random_state=42, **hyperparams)
        elif model_choice == "Random Forest":
            clf = RandomForestClassifier(random_state=42, **hyperparams)
        else:
            clf = LogisticRegression(random_state=42, max_iter=1000)
        
        clf.fit(X_train_sel, y_train)
        y_pred = clf.predict(X_test_sel)
        y_prob = clf.predict_proba(X_test_sel)[:, 1]
        
        st.session_state['clf'] = clf
        st.session_state['selected_features'] = selected_features
        st.session_state['X_test_sel'] = X_test_sel
        st.session_state['y_test'] = y_test
        st.session_state['y_pred'] = y_pred
        st.session_state['y_prob'] = y_prob
        
        st.subheader("üèÜ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏")
        st.write(f"–ú–æ–¥–µ–ª—å: **{model_choice}**")
        st.write("–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã:", hyperparams)
        st.metric("–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)", f"{accuracy_score(y_test, y_pred):.3f}")
        st.metric("ROC AUC", f"{roc_auc_score(y_test, y_prob):.3f}")
        st.metric("F1-–º–µ—Ä–∞", f"{f1_score(y_test, y_pred):.3f}")
        st.metric("Precision", f"{precision_score(y_test, y_pred):.3f}")
        st.metric("Recall", f"{recall_score(y_test, y_pred):.3f}")
        
        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(y_test, y_pred)
        fig_cm, ax_cm = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax=ax_cm)
        ax_cm.set_xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
        ax_cm.set_ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
        ax_cm.set_title("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
        st.pyplot(fig_cm)
        
        # ROC-–∫—Ä–∏–≤–∞—è (Plotly)
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_auc_val = auc(fpr, tpr)
        fig_roc = px.area(
            x=fpr, y=tpr,
            title=f'ROC-–∫—Ä–∏–≤–∞—è (AUC = {roc_auc_val:.2f})',
            labels={'x': 'False Positive Rate', 'y': 'True Positive Rate'},
        )
        fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)
        fig_roc.update_traces(fillcolor='rgba(99, 255, 132, 0.6)')
        st.plotly_chart(fig_roc)
        
        st.subheader("–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        st.text(classification_report(y_test, y_pred))

# –ï–¥–∏–Ω–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
if single_predict_button:
    if 'clf' not in st.session_state:
        st.warning("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å!")
    else:
        sample_df = pd.DataFrame([prediction_data])
        sample_sel = sample_df[st.session_state['selected_features']]
        sample_scaled = scaler.transform(sample_sel)
        pred_class = st.session_state['clf'].predict(sample_scaled)
        pred_prob = st.session_state['clf'].predict_proba(sample_scaled)[:, 1]
        st.subheader("‚ú® –†–µ–∑—É–ª—å—Ç–∞—Ç –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
        st.write(f"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å: **{pred_class[0]}**")
        st.write(f"–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1: **{pred_prob[0]:.3f}**")

st.markdown("---")
st.markdown("–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–æ–º–ø–∞–Ω–∏–µ–π Jamshed Corporation —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å ZyplAI")
