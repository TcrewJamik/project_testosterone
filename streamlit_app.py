import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (accuracy_score, roc_auc_score, f1_score, precision_score, 
                             recall_score, roc_curve, auc, confusion_matrix, classification_report)
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier
import requests
import io

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(page_title="–ê–Ω–∞–ª–∏–∑ –¥–µ—Ñ–∏—Ü–∏—Ç–∞ —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞", page_icon="‚öôÔ∏è", layout="wide")
st.title("–ê–Ω–∞–ª–∏–∑ –¥–µ—Ñ–∏—Ü–∏—Ç–∞ —Ç–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞")

# ------------------------ –ó–ê–ì–†–£–ó–ö–ê –î–ê–ù–ù–´–• ------------------------
raw_url = "https://raw.githubusercontent.com/TcrewJamik/project_testosterone/refs/heads/master/ptestost.xlsx"
try:
    response = requests.get(raw_url)
    response.raise_for_status()
    excel_file = io.BytesIO(response.content)
    df = pd.read_excel(excel_file)

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
    df = df.rename(columns={
        'Age': '–í–æ–∑—Ä–∞—Å—Ç',
        'DM': '–ù–∞–ª–∏—á–∏–µ –î–∏–∞–±–µ—Ç–∞',
        'TG': '–¢—Ä–∏–≥–ª–∏—Ü–µ—Ä–∏–¥—ã (–º–≥/–¥–ª)',
        'HT': '–ù–∞–ª–∏—á–∏–µ –ì–∏–ø–µ—Ä—Ç–æ–Ω–∏–∏',
        'HDL': 'HDL_—Ö–æ–ª–µ—Å—Ç–µ—Ä–∏–Ω',
        'AC': '–û–∫—Ä—É–∂–Ω–æ—Å—Ç—å_—Ç–∞–ª–∏–∏',
        'T': '–î–µ—Ñ–∏—Ü–∏—Ç –¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞'
    })
    st.success("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏–∑ GitHub!")
except Exception as e:
    st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
    st.stop()

# ------------------------ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û –î–ê–ù–ù–´–• ------------------------
with st.expander("–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö"):
    st.dataframe(df.head())
    st.write("–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    st.dataframe(df.describe())
    st.write("–ü—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:")
    st.write(df.isna().sum())

# ------------------------ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø ------------------------
with st.expander("–í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö"):
    st.subheader("–ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    fig, axes = plt.subplots(2, 3, figsize=(15, 10))
    for i, column in enumerate(df.columns[:6]):  # –ø—Ä–∏–º–µ—Ä –¥–ª—è –ø–µ—Ä–≤—ã—Ö 6 —Å—Ç–æ–ª–±—Ü–æ–≤
        sns.histplot(df[column], bins=30, kde=True, ax=axes[i // 3, i % 3])
        axes[i // 3, i % 3].set_title(f'–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {column}')
    st.pyplot(fig)

    st.subheader("–ö–æ—Ä—Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
    fig_corr = plt.figure(figsize=(10, 8))
    sns.heatmap(df.corr(), annot=True, cmap='coolwarm', fmt=".2f")
    st.pyplot(fig_corr)

# ------------------------ –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –î–ê–ù–ù–´–• ------------------------
target = df['–î–µ—Ñ–∏—Ü–∏—Ç –¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞']
X = df.drop(columns=['–î–µ—Ñ–∏—Ü–∏—Ç –¢–µ—Å—Ç–æ—Å—Ç–µ—Ä–æ–Ω–∞'])
y = target

# –ï—Å–ª–∏ –µ—Å—Ç—å –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã (object), –∫–æ–¥–∏—Ä—É–µ–º –∏—Ö
non_numeric = X.select_dtypes(include=['object']).columns
if len(non_numeric) > 0:
    le = LabelEncoder()
    for col in non_numeric:
        X[col] = le.fit_transform(X[col])

# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

# –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
feature_names = X.columns.tolist()

# ------------------------ –ë–û–ö–û–í–ê–Ø –ü–ê–ù–ï–õ–¨ ------------------------
with st.sidebar:
    st.header("üõ†Ô∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏")

    # –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
    model_choice = st.selectbox(
        "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å:",
        ["–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è", "CatBoost", "XGBoost", "Decision Tree", "Random Forest"]
    )

    # –ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã
    hyperparams = {}
    if model_choice == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è":
        hyperparams['C'] = st.slider("C (–†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è)", 0.001, 10.0, 1.0, step=0.01)
        penalty_options = ['l1', 'l2', 'none']
        hyperparams['penalty'] = st.selectbox("Penalty", penalty_options, index=1)
        solver_options = ['lbfgs', 'liblinear']
        if hyperparams['penalty'] == 'l1':
            solver_options = ['liblinear', 'saga']
        elif hyperparams['penalty'] == 'none':
            solver_options = ['lbfgs', 'newton-cg', 'sag', 'saga']
        hyperparams['solver'] = st.selectbox("Solver", solver_options, index=0)

    elif model_choice == "CatBoost":
        hyperparams['depth'] = st.slider("–ì–ª—É–±–∏–Ω–∞ (depth)", 4, 10, 6, step=1)
        hyperparams['iterations'] = st.slider("Iterations", 50, 300, 200, step=10)
        hyperparams['learning_rate'] = st.slider("Learning rate", 0.01, 0.5, 0.1, step=0.01)

    elif model_choice == "XGBoost":
        hyperparams['max_depth'] = st.slider("max_depth", 3, 10, 6, step=1)
        hyperparams['n_estimators'] = st.slider("n_estimators", 50, 300, 200, step=10)
        hyperparams['learning_rate'] = st.slider("learning_rate", 0.01, 0.5, 0.1, step=0.01)
        hyperparams['scale_pos_weight'] = st.slider("scale_pos_weight", 1, 10, 1, step=1)

    elif model_choice == "Decision Tree":
        hyperparams['criterion'] = st.selectbox("Criterion", ['gini', 'entropy'], index=0)
        hyperparams['max_depth'] = st.slider("max_depth", 1, 20, 5, step=1)
        hyperparams['min_samples_split'] = st.slider("min_samples_split", 2, 20, 2, step=1)
        hyperparams['min_samples_leaf'] = st.slider("min_samples_leaf", 1, 10, 1, step=1)

    elif model_choice == "Random Forest":
        hyperparams['n_estimators'] = st.slider("n_estimators", 50, 300, 200, step=10)
        hyperparams['max_depth'] = st.slider("max_depth", 1, 20, 10, step=1)
        hyperparams['min_samples_split'] = st.slider("min_samples_split", 2, 20, 2, step=1)
        hyperparams['min_samples_leaf'] = st.slider("min_samples_leaf", 1, 10, 1, step=1)

    st.markdown("---")
    st.header("üìä –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏ –µ–¥–∏–Ω–∏—á–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")

    # –í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    selected_features = st.multiselect(
        "–í—ã–±–µ—Ä–∏—Ç–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è:",
        feature_names,
        default=feature_names  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ
    )

    # –ö–Ω–æ–ø–∫–∞ –æ–±—É—á–µ–Ω–∏—è
    train_button = st.button("üî• –û–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å")

    st.markdown("---")
    st.subheader("–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –≤—Ö–æ–¥–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")

    prediction_data = {}
    if selected_features:
        for feature in selected_features:
            # –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è —Å–ª–∞–π–¥–µ—Ä–∞
            min_val = float(X_train[feature].min())
            max_val = float(X_train[feature].max())
            default_val = float(X_train[feature].mean())
            prediction_data[feature] = st.slider(
                f"–ó–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è {feature}:",
                min_val,
                max_val,
                default_val
            )

    # –ö–Ω–æ–ø–∫–∞ –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    single_predict_button = st.button("‚ú® –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –¥–ª—è –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –æ–±—Ä–∞–∑—Ü–∞")

# ------------------------ –û–°–ù–û–í–ù–ê–Ø –û–ë–õ–ê–°–¢–¨: –û–¶–ï–ù–ö–ê –ú–û–î–ï–õ–ò ------------------------
if train_button:
    if not selected_features:
        st.warning("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø—Ä–∏–∑–Ω–∞–∫ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è.")
    else:
        # –û—Ç–±–æ—Ä –Ω—É–∂–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        selected_idx = [feature_names.index(feat) for feat in selected_features]
        X_train_sel = X_train_scaled[:, selected_idx]
        X_test_sel = X_test_scaled[:, selected_idx]

        # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞
        if model_choice == "–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è":
            clf = LogisticRegression(random_state=42, max_iter=1000, **hyperparams)
        elif model_choice == "CatBoost":
            clf = CatBoostClassifier(random_state=42, verbose=0, **hyperparams)
        elif model_choice == "XGBoost":
            clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss', **hyperparams)
        elif model_choice == "Decision Tree":
            clf = DecisionTreeClassifier(random_state=42, **hyperparams)
        elif model_choice == "Random Forest":
            clf = RandomForestClassifier(random_state=42, **hyperparams)
        else:
            clf = LogisticRegression(random_state=42, max_iter=1000)

        clf.fit(X_train_sel, y_train)
        y_pred = clf.predict(X_test_sel)
        y_prob = clf.predict_proba(X_test_sel)[:, 1]

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ session_state
        st.session_state['clf'] = clf
        st.session_state['selected_features'] = selected_features
        st.session_state['X_test_sel'] = X_test_sel
        st.session_state['y_test'] = y_test
        st.session_state['y_pred'] = y_pred
        st.session_state['y_prob'] = y_prob

        # –í—ã–≤–æ–¥–∏–º –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏
        st.subheader("üèÜ –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏")
        st.write(f"**–ú–æ–¥–µ–ª—å**: {model_choice}")
        st.write("**–ì–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã**:", hyperparams)
        st.metric("–¢–æ—á–Ω–æ—Å—Ç—å (Accuracy)", f"{accuracy_score(y_test, y_pred):.3f}")
        st.metric("ROC AUC", f"{roc_auc_score(y_test, y_prob):.3f}")
        st.metric("F1-–º–µ—Ä–∞", f"{f1_score(y_test, y_pred):.3f}")
        st.metric("Precision", f"{precision_score(y_test, y_pred):.3f}")
        st.metric("Recall", f"{recall_score(y_test, y_pred):.3f}")

        # –ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫
        cm = confusion_matrix(y_test, y_pred)
        fig_cm, ax_cm = plt.subplots(figsize=(6, 4))
        sns.heatmap(cm, annot=True, fmt='d', cmap='viridis', ax=ax_cm)
        ax_cm.set_xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
        ax_cm.set_ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–µ –∫–ª–∞—Å—Å—ã")
        ax_cm.set_title("–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫")
        st.pyplot(fig_cm)

        # ROC-–∫—Ä–∏–≤–∞—è
        fpr, tpr, _ = roc_curve(y_test, y_prob)
        roc_auc_val = auc(fpr, tpr)
        fig_roc = px.area(
            x=fpr, y=tpr,
            title=f'ROC-–∫—Ä–∏–≤–∞—è (AUC = {roc_auc_val:.2f})',
            labels={'x': 'False Positive Rate', 'y': 'True Positive Rate'},
        )
        fig_roc.add_shape(
            type='line', line=dict(dash='dash'),
            x0=0, x1=1, y0=0, y1=1
        )
        fig_roc.update_traces(fillcolor='rgba(99, 255, 132, 0.6)')
        st.plotly_chart(fig_roc)

        st.subheader("–û—Ç—á–µ—Ç –æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        st.text(classification_report(y_test, y_pred))

# ------------------------ –û–°–ù–û–í–ù–ê–Ø –û–ë–õ–ê–°–¢–¨: –ï–î–ò–ù–ò–ß–ù–û–ï –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï ------------------------
if single_predict_button:
    if 'clf' not in st.session_state:
        st.warning("–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å!")
    else:
        # –§–æ—Ä–º–∏—Ä—É–µ–º DataFrame –∏–∑ –≤–≤–µ–¥—ë–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –∑–Ω–∞—á–µ–Ω–∏–π
        sample_df = pd.DataFrame([prediction_data])
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        sample_sel = sample_df[st.session_state['selected_features']]
        # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º
        sample_scaled = scaler.transform(sample_sel)

        pred_class = st.session_state['clf'].predict(sample_scaled)
        pred_prob = st.session_state['clf'].predict_proba(sample_scaled)[:, 1]

        # –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç–¥–µ–ª—å–Ω–æ
        st.subheader("üîÆ –†–µ–∑—É–ª—å—Ç–∞—Ç –µ–¥–∏–Ω–∏—á–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è")
        st.write(f"**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å**: {pred_class[0]}")
        st.write(f"**–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–ª–∞—Å—Å–∞ 1**: {pred_prob[0]:.3f}")

st.markdown("---")
st.markdown("–†–∞–∑—Ä–∞–±–æ—Ç–∞–Ω–æ –∫–æ–º–ø–∞–Ω–∏–µ–π Jamshed Corporation —Å–æ–≤–º–µ—Å—Ç–Ω–æ —Å ZyplAI")

–¥–æ–±–∞–≤—å –≤–∞–∂–Ω–æ—Å—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
